{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "2.2.4-tf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "from collections import deque\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import model_from_config\n",
    "from keras import backend as K\n",
    "\n",
    "print(tf.__version__)\n",
    "print(tf.keras.__version__)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionValueNetwork:\n",
    "    def __init__(self, network_config):\n",
    "        self.state_dim = network_config.get(\"state_dim\")\n",
    "        self.num_hidden_units = network_config.get(\"num_hidden_units\")\n",
    "        self.num_actions = network_config.get(\"num_actions\")\n",
    "        \n",
    "        self.rand_generator = np.random.RandomState(network_config.get(\"seed\"))\n",
    "        \n",
    "        # Specify self.layer_size which shows the number of nodes in each layer\n",
    "        self.layer_sizes = np.array([self.state_dim, self.num_hidden_units, self.num_actions])\n",
    "        \n",
    "        # Initialize the weights of the neural network\n",
    "        # self.weights is an array of dictionaries with each dictionary corresponding to \n",
    "        # the weights from one layer to the next. Each dictionary includes W and b\n",
    "        self.weights = [dict() for i in range(0, len(self.layer_sizes) - 1)]\n",
    "        for i in range(0, len(self.layer_sizes) - 1):\n",
    "            self.weights[i]['W'] = self.init_saxe(self.layer_sizes[i], self.layer_sizes[i + 1])\n",
    "            self.weights[i]['b'] = np.zeros((1, self.layer_sizes[i + 1]))\n",
    "    \n",
    "    def get_action_values(self, s):\n",
    "        W0, b0 = self.weights[0]['W'], self.weights[0]['b']\n",
    "        psi = np.dot(s, W0) + b0\n",
    "        x = np.maximum(psi, 0)\n",
    "        \n",
    "        W1, b1 = self.weights[1]['W'], self.weights[1]['b']\n",
    "        q_vals = np.dot(x, W1) + b1\n",
    "\n",
    "        return q_vals\n",
    "    \n",
    "    def get_TD_update(self, s, delta_mat):\n",
    "        W0, b0 = self.weights[0]['W'], self.weights[0]['b']\n",
    "        W1, b1 = self.weights[1]['W'], self.weights[1]['b']\n",
    "        \n",
    "        psi = np.dot(s, W0) + b0\n",
    "        x = np.maximum(psi, 0)\n",
    "        dx = (psi > 0).astype(float)\n",
    "\n",
    "        # td_update has the same structure as self.weights, that is an array of dictionaries.\n",
    "        # td_update[0][\"W\"], td_update[0][\"b\"], td_update[1][\"W\"], and td_update[1][\"b\"] have the same shape as \n",
    "        # self.weights[0][\"W\"], self.weights[0][\"b\"], self.weights[1][\"W\"], and self.weights[1][\"b\"] respectively\n",
    "        td_update = [dict() for i in range(len(self.weights))]\n",
    "         \n",
    "        v = delta_mat\n",
    "        td_update[1]['W'] = np.dot(x.T, v) * 1. / s.shape[0]\n",
    "        td_update[1]['b'] = np.sum(v, axis=0, keepdims=True) * 1. / s.shape[0]\n",
    "        \n",
    "        v = np.dot(v, W1.T) * dx\n",
    "        td_update[0]['W'] = np.dot(s.T, v) * 1. / s.shape[0]\n",
    "        td_update[0]['b'] = np.sum(v, axis=0, keepdims=True) * 1. / s.shape[0]\n",
    "                \n",
    "        return td_update\n",
    "    \n",
    "    # You may wish to read the relevant paper for more information on this weight initialization\n",
    "    # (Exact solutions to the nonlinear dynamics of learning in deep linear neural networks by Saxe, A et al., 2013)\n",
    "    def init_saxe(self, rows, cols):\n",
    "        tensor = self.rand_generator.normal(0, 1, (rows, cols))\n",
    "        if rows < cols:\n",
    "            tensor = tensor.T\n",
    "        tensor, r = np.linalg.qr(tensor)\n",
    "        d = np.diag(r, 0)\n",
    "        ph = np.sign(d)\n",
    "        tensor *= ph\n",
    "\n",
    "        if rows < cols:\n",
    "            tensor = tensor.T\n",
    "        return tensor\n",
    "    \n",
    "    # Work Required: No.\n",
    "    def get_weights(self):\n",
    "        return deepcopy(self.weights)\n",
    "    \n",
    "    # Work Required: No.\n",
    "    def set_weights(self, weights):\n",
    "        self.weights = deepcopy(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam():\n",
    "    def __init__(self, layer_sizes, \n",
    "                 optimizer_info):\n",
    "        self.layer_sizes = layer_sizes\n",
    "\n",
    "        # Specify Adam algorithm's hyper parameters\n",
    "        self.step_size = optimizer_info.get(\"step_size\")\n",
    "        self.beta_m = optimizer_info.get(\"beta_m\")\n",
    "        self.beta_v = optimizer_info.get(\"beta_v\")\n",
    "        self.epsilon = optimizer_info.get(\"epsilon\")\n",
    "        \n",
    "        # Initialize Adam algorithm's m and v\n",
    "        self.m = [dict() for i in range(1, len(self.layer_sizes))]\n",
    "        self.v = [dict() for i in range(1, len(self.layer_sizes))]\n",
    "        \n",
    "        for i in range(0, len(self.layer_sizes) - 1):\n",
    "            # Hint: The initialization for m and v should look very much like the initializations of the weights\n",
    "            # except for the fact that initialization here is to zeroes (see description above.)\n",
    "            self.m[i][\"W\"] = np.zeros((self.layer_sizes[i], self.layer_sizes[i + 1]))\n",
    "            self.m[i][\"b\"] = np.zeros((1, self.layer_sizes[i + 1]))\n",
    "            self.v[i][\"W\"] = np.zeros((self.layer_sizes[i], self.layer_sizes[i + 1]))\n",
    "            self.v[i][\"b\"] = np.zeros((1, self.layer_sizes[i + 1]))\n",
    "            \n",
    "        # Notice that to calculate m_hat and v_hat, we use powers of beta_m and beta_v to \n",
    "        # the time step t. We can calculate these powers using an incremental product. At initialization then, \n",
    "        # beta_m_product and beta_v_product should be ...? (Note that timesteps start at 1 and if we were to \n",
    "        # start from 0, the denominator would be 0.)\n",
    "        self.beta_m_product = self.beta_m\n",
    "        self.beta_v_product = self.beta_v\n",
    "    \n",
    "    # Work Required: Yes. Fill in the weight updates (~5-7 lines).\n",
    "    def update_weights(self, weights, td_errors_times_gradients):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            weights (Array of dictionaries): The weights of the neural network.\n",
    "            td_errors_times_gradients (Array of dictionaries): The gradient of the \n",
    "            action-values with respect to the network's weights times the TD-error\n",
    "        Returns:\n",
    "            The updated weights (Array of dictionaries).\n",
    "        \"\"\"\n",
    "        for i in range(len(weights)):\n",
    "            for param in weights[i].keys():\n",
    "                # Hint: Follow the equations above. First, you should update m and v and then compute \n",
    "                # m_hat and v_hat. Finally, compute how much the weights should be incremented by.\n",
    "                g_t = td_errors_times_gradients[i][param]\n",
    "                self.m[i][param] = self.beta_m*self.m[i][param] + (1-self.beta_m)*g_t\n",
    "                self.v[i][param] = self.beta_v*self.v[i][param] + (1-self.beta_v)*np.square(g_t)\n",
    "                m_hat = self.m[i][param] / (1-self.beta_m_product)\n",
    "                v_hat = self.v[i][param] / (1-self.beta_v_product)\n",
    "                weight_update = (self.step_size / (np.sqrt(v_hat) + self.epsilon)) * m_hat\n",
    "                \n",
    "                weights[i][param] = weights[i][param] + weight_update\n",
    "        # Notice that to calculate m_hat and v_hat, we use powers of beta_m and beta_v to \n",
    "        ### update self.beta_m_product and self.beta_v_product\n",
    "        self.beta_m_product *= self.beta_m\n",
    "        self.beta_v_product *= self.beta_v\n",
    "        \n",
    "        return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, size, minibatch_size, seed):\n",
    "        self.buffer = []\n",
    "        self.minibatch_size = minibatch_size\n",
    "        self.rand_generator = np.random.RandomState(seed)\n",
    "        self.max_size = size\n",
    "\n",
    "    def append(self, state, action, reward, terminal, next_state):\n",
    "        if len(self.buffer) == self.max_size:\n",
    "            del self.buffer[0]\n",
    "        self.buffer.append([state, action, reward, terminal, next_state])\n",
    "\n",
    "    def sample(self):\n",
    "        idxs = self.rand_generator.choice(np.arange(len(self.buffer)), size=self.minibatch_size)\n",
    "        return [self.buffer[idx] for idx in idxs]\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.buffer)\n",
    "    \n",
    "    def save_replay_buffer(self):\n",
    "        self.file_count += 1\n",
    "        states, actions, rewards, terminals, next_states = map(list, zip(*self.buffer))\n",
    "        states = np.concatenate(states)\n",
    "        next_states = np.concatenate(next_states)\n",
    "        rewards = np.array(rewards)\n",
    "        terminals = np.array(terminals)        \n",
    "        np.savez(\"LunarLander_{}\".format(self.file_count), states=states, actions=actions, rewards=rewards, next_states=next_states, terminals=terminals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(action_values, tau=1.0):\n",
    "    # Compute the preferences by dividing the action-values by the temperature parameter tau\n",
    "    preferences = np.divide(action_values, tau)\n",
    "\n",
    "    # Compute the maximum preference across the actions\n",
    "    max_preference = np.amax(preferences, axis=1)\n",
    "    \n",
    "    \n",
    "    # Reshape max_preference array which has shape [Batch,] to [Batch, 1]. This allows NumPy broadcasting \n",
    "    # when subtracting the maximum preference from the preference of each action.\n",
    "    reshaped_max_preference = max_preference.reshape((-1, 1))\n",
    "    \n",
    "    # Compute the numerator, i.e., the exponential of the preference - the max preference.\n",
    "    exp_preferences = np.exp(preferences - reshaped_max_preference)\n",
    "    # Compute the denominator, i.e., the sum over the numerator along the actions axis.\n",
    "    sum_of_exp_preferences = np.sum(exp_preferences, axis=1)\n",
    "    \n",
    "    \n",
    "    # Reshape sum_of_exp_preferences array which has shape [Batch,] to [Batch, 1] to  allow for NumPy broadcasting \n",
    "    # when dividing the numerator by the denominator.\n",
    "    reshaped_sum_of_exp_preferences = sum_of_exp_preferences.reshape((-1, 1))\n",
    "    \n",
    "    # Compute the action probabilities according to the equation in the previous cell.\n",
    "    action_probs = np.divide(exp_preferences, reshaped_sum_of_exp_preferences)    \n",
    "    \n",
    "    # squeeze() removes any singleton dimensions. It is used here because this function is used in the \n",
    "    # agent policy when selecting an action (for which the batch dimension is 1.) As np.random.choice is used in \n",
    "    # the agent policy and it expects 1D arrays, we need to remove this singleton batch dimension.\n",
    "    action_probs = action_probs.squeeze()\n",
    "    return action_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_td_error(states, next_states, actions, rewards, discount, terminals, network, current_q, tau):\n",
    "    # Note: Here network is the latest state of the network that is getting replay updates. In other words, \n",
    "    # the network represents Q_{t+1}^{i} whereas current_q represents Q_t, the fixed network used for computing the \n",
    "    # targets, and particularly, the action-values at the next-states.\n",
    "    \n",
    "    # Compute action values at next states using current_q network\n",
    "    # Note that q_next_mat is a 2D array of shape (batch_size, num_actions)\n",
    "    q_next_mat = current_q.get_action_values(next_states)\n",
    "    \n",
    "    # Compute policy at next state by passing the action-values in q_next_mat to softmax()\n",
    "    # Note that probs_mat is a 2D array of shape (batch_size, num_actions)\n",
    "    probs_mat = softmax(q_next_mat, tau)\n",
    "    \n",
    "    # Compute the estimate of the next state value, v_next_vec.\n",
    "    # Hint: sum the action-values for the next_states weighted by the policy, probs_mat. Then, multiply by\n",
    "    # (1 - terminals) to make sure v_next_vec is zero for terminal next states.\n",
    "    # Note that v_next_vec is a 1D array of shape (batch_size,)\n",
    "    v_next_vec = np.average(q_next_mat, weights=probs_mat, axis=1)\n",
    "    v_next_vec = v_next_vec * (1-terminals)\n",
    "    \n",
    "    # Compute Expected Sarsa target\n",
    "    # Note that target_vec is a 1D array of shape (batch_size,)\n",
    "    target_vec = rewards + discount*v_next_vec\n",
    "    \n",
    "    # Compute action values at the current states for all actions using network\n",
    "    # Note that q_mat is a 2D array of shape (batch_size, num_actions)\n",
    "    q_mat = network.get_action_values(states)\n",
    "    \n",
    "    # Batch Indices is an array from 0 to the batch size - 1. \n",
    "    batch_indices = np.arange(q_mat.shape[0])\n",
    "\n",
    "    # Compute q_vec by selecting q(s, a) from q_mat for taken actions\n",
    "    # Use batch_indices as the index for the first dimension of q_mat\n",
    "    # Note that q_vec is a 1D array of shape (batch_size)\n",
    "    q_vec = q_mat[batch_indices, actions]\n",
    "    \n",
    "    # Compute TD errors for actions taken\n",
    "    # Note that delta_vec is a 1D array of shape (batch_size)\n",
    "    delta_vec = target_vec - q_vec\n",
    "    \n",
    "    return delta_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_network(experiences, discount, optimizer, network, current_q, tau):\n",
    "    # Get states, action, rewards, terminals, and next_states from experiences\n",
    "    states, actions, rewards, terminals, next_states = map(list, zip(*experiences))\n",
    "    states = np.concatenate(states)\n",
    "    next_states = np.concatenate(next_states)\n",
    "    rewards = np.array(rewards)\n",
    "    terminals = np.array(terminals)\n",
    "    batch_size = states.shape[0]\n",
    "\n",
    "    # Compute TD error using the get_td_error function\n",
    "    # Note that q_vec is a 1D array of shape (batch_size)\n",
    "    delta_vec = get_td_error(states, next_states, actions, rewards, discount, terminals, network, current_q, tau)\n",
    "\n",
    "    # Batch Indices is an array from 0 to the batch_size - 1. \n",
    "    batch_indices = np.arange(batch_size)\n",
    "\n",
    "    # Make a td error matrix of shape (batch_size, num_actions)\n",
    "    # delta_mat has non-zero value only for actions taken\n",
    "    delta_mat = np.zeros((batch_size, network.num_actions))\n",
    "    delta_mat[batch_indices, actions] = delta_vec\n",
    "\n",
    "    # Pass delta_mat to compute the TD errors times the gradients of the network's weights from back-propagation\n",
    "    td_update = network.get_TD_update(states, delta_mat)\n",
    "    \n",
    "    # Pass network.get_weights and the td_update to the optimizer to get updated weights\n",
    "    weights = optimizer.update_weights(network.get_weights(), td_update)\n",
    "    \n",
    "    network.set_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self):\n",
    "        self.name = \"expected_sarsa_agent\"\n",
    "        self.total_count = 0\n",
    "        \n",
    "    # Work Required: No.\n",
    "    def agent_init(self, agent_config):\n",
    "        self.replay_buffer = ReplayBuffer(agent_config['replay_buffer_size'], \n",
    "                                          agent_config['minibatch_sz'], agent_config.get(\"seed\"))\n",
    "        self.network = ActionValueNetwork(agent_config['network_config'])\n",
    "        self.optimizer = Adam(self.network.layer_sizes, agent_config[\"optimizer_config\"])\n",
    "        self.num_actions = agent_config['network_config']['num_actions']\n",
    "        self.num_replay = agent_config['num_replay_updates_per_step']\n",
    "        self.discount = agent_config['gamma']\n",
    "        self.tau = agent_config['tau']\n",
    "        \n",
    "        self.rand_generator = np.random.RandomState(agent_config.get(\"seed\"))\n",
    "        \n",
    "        self.last_state = None\n",
    "        self.last_action = None\n",
    "        \n",
    "        self.sum_rewards = 0\n",
    "        self.episode_steps = 0\n",
    "\n",
    "    def policy(self, state):\n",
    "        action_values = self.network.get_action_values(state)\n",
    "        probs_batch = softmax(action_values, self.tau)\n",
    "        action = self.rand_generator.choice(self.num_actions, p=probs_batch.squeeze())\n",
    "        return action\n",
    "\n",
    "    def agent_start(self, state):\n",
    "        self.sum_rewards = 0\n",
    "        self.episode_steps = 0\n",
    "        self.last_state = np.array([state])\n",
    "        self.last_action = self.policy(self.last_state)\n",
    "        return self.last_action\n",
    "\n",
    "    def agent_step(self, reward, state):\n",
    "        self.sum_rewards += reward\n",
    "        self.episode_steps += 1\n",
    "\n",
    "        # Make state an array of shape (1, state_dim) to add a batch dimension and\n",
    "        # to later match the get_action_values() and get_TD_update() functions\n",
    "        state = np.array([state])\n",
    "\n",
    "        # Select action\n",
    "        action = self.policy(state)\n",
    "        \n",
    "        # Append new experience to replay buffer\n",
    "        self.replay_buffer.append(self.last_state, self.last_action, reward, 0, state)\n",
    "        \n",
    "        # Perform replay steps:\n",
    "        if self.replay_buffer.size() > self.replay_buffer.minibatch_size:\n",
    "            current_q = deepcopy(self.network)\n",
    "            for _ in range(self.num_replay):\n",
    "                self.total_count +=1\n",
    "                # Get sample experiences from the replay buffer\n",
    "                experiences = self.replay_buffer.sample()\n",
    "                \n",
    "                # Call optimize_network to update the weights of the network (~1 Line)\n",
    "                optimize_network(experiences, self.discount, self.optimizer, self.network, current_q, self.tau)\n",
    "                \n",
    "        # Update the last state and last action.\n",
    "        self.last_state = state\n",
    "        self.last_action = action\n",
    "        \n",
    "        return action\n",
    "\n",
    "    def agent_end(self, reward):\n",
    "        self.sum_rewards += reward\n",
    "        self.episode_steps += 1\n",
    "        \n",
    "        # Set terminal state to an array of zeros\n",
    "        state = np.zeros_like(self.last_state)\n",
    "\n",
    "        # Append new experience to replay buffer\n",
    "        self.replay_buffer.append(self.last_state, self.last_action, reward, 1, state)\n",
    "        \n",
    "        # Perform replay steps:\n",
    "        if self.replay_buffer.size() > self.replay_buffer.minibatch_size:\n",
    "            current_q = deepcopy(self.network)\n",
    "            for _ in range(self.num_replay):        \n",
    "                self.total_count+=1\n",
    "                # Get sample experiences from the replay buffer\n",
    "                experiences = self.replay_buffer.sample()\n",
    "                \n",
    "                # Call optimize_network to update the weights of the network\n",
    "                optimize_network(experiences, self.discount, self.optimizer, self.network, current_q, self.tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# Environment\n",
    "env_name = 'LunarLander-v2'\n",
    "env = gym.make(env_name)\n",
    "\n",
    "state_dim = env.observation_space.shape[0]\n",
    "num_actions = env.action_space.n\n",
    "\n",
    "print(state_dim)\n",
    "print(num_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [10:40<00:00,  2.14s/it]\n"
     ]
    }
   ],
   "source": [
    "# Agent Parameters\n",
    "agent_parameters = {\n",
    "    'network_config': {\n",
    "        'state_dim': state_dim,\n",
    "        'num_hidden_units': 256,\n",
    "        'num_actions': num_actions\n",
    "    },\n",
    "    'optimizer_config': {\n",
    "        'step_size': 1e-3,\n",
    "        'beta_m': 0.9, \n",
    "        'beta_v': 0.999,\n",
    "        'epsilon': 1e-8\n",
    "    },\n",
    "    'replay_buffer_size': 50000,\n",
    "    'minibatch_sz': 8,\n",
    "    'num_replay_updates_per_step': 4,\n",
    "    'gamma': 0.99,\n",
    "    'tau': 0.001\n",
    "}\n",
    "\n",
    "# Training Parameters\n",
    "training_parameters = {\n",
    "    \"num_runs\" : 1,\n",
    "    \"num_episodes\" : 300,\n",
    "    \"max_steps\" : 1000\n",
    "}\n",
    "\n",
    "def train_episode(env, agent, max_steps):\n",
    "    done = False\n",
    "    steps = 0\n",
    "    episode_return = 0.0\n",
    "    \n",
    "    observation = env.reset()\n",
    "    action = agent.agent_start(observation)\n",
    "\n",
    "    while not done and steps<max_steps:\n",
    "        steps += 1\n",
    "        next_observation, reward, done, _ = env.step(action)\n",
    "        episode_return += reward\n",
    "        \n",
    "        if (done==True):\n",
    "            agent.agent_end(reward)\n",
    "        else:\n",
    "            action = agent.agent_step(reward, next_observation)\n",
    "            observation = next_observation\n",
    "\n",
    "    return episode_return, steps, done\n",
    "\n",
    "\n",
    "def train_agent(env, agent_parameters, training_parameters):\n",
    "    agent = Agent()\n",
    "    agent.agent_init(agent_parameters)\n",
    "    \n",
    "    agent_sum_reward = np.zeros((training_parameters[\"num_runs\"], \n",
    "                                 training_parameters[\"num_episodes\"]))\n",
    "    \n",
    "    for run in range(1, training_parameters[\"num_runs\"]+1):\n",
    "        for episode in tqdm(range(1, training_parameters[\"num_episodes\"]+1)):\n",
    "            # run episode\n",
    "            episode_reward, steps, done = train_episode(env, agent, training_parameters[\"max_steps\"])\n",
    "            agent_sum_reward[run - 1, episode - 1] = episode_reward\n",
    "\n",
    "    return agent, agent_sum_reward\n",
    "\n",
    "agent, agent_sum_reward = train_agent(env, agent_parameters, training_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x14b6ce890>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(agent_sum_reward[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-11.354411803888055\n"
     ]
    }
   ],
   "source": [
    "done = False\n",
    "render = True\n",
    "rewards = 0\n",
    "observation = env.reset()\n",
    "while not done:\n",
    "    if (render is True):\n",
    "        env.render()\n",
    "    observation = np.expand_dims(observation, axis=0)\n",
    "    action = agent.policy(observation)\n",
    "    observation, reward, done, _ = env.step(action)\n",
    "    rewards += reward\n",
    "    \n",
    "print(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16774320\n"
     ]
    }
   ],
   "source": [
    "print(agent.total_count*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
